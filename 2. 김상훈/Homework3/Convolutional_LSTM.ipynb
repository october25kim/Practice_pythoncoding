{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import math\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from pandas.core.common import flatten\n",
    "import itertools\n",
    "\n",
    "from numpy import unique\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling3D\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0714 07:33:49.851440 140431699314432 deprecation.py:323] From <ipython-input-2-088aa1a5baab>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/Workspace/jiyoon/analysis'\n",
    "code_dir = os.path.join(project_dir, 'code')\n",
    "# save_dir = os.path.join(project_dir, 'results')\n",
    "save_dir = os.path.join(project_dir, 'results')\n",
    "\n",
    "\n",
    "#X_train = np.load(os.path.join(save_dir, 'X_train_10.npy'))  \n",
    "#X_test = np.load(os.path.join(save_dir, 'X_test_10.npy'))  \n",
    "#y_train = np.load(os.path.join(save_dir, 'y_train_10.npy'))  \n",
    "#y_test = np.load(os.path.join(save_dir, 'y_test_10.npy'))  \n",
    "\n",
    "X_train = np.load(os.path.join(save_dir, 'X_train_10_total.npy'))  \n",
    "X_test = np.load(os.path.join(save_dir, 'X_test_10_total.npy'))  \n",
    "y_train = np.load(os.path.join(save_dir, 'y_train_10_total.npy'))  \n",
    "y_test = np.load(os.path.join(save_dir, 'y_test_10_total.npy'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "y_train = labelencoder.fit_transform(y_train) # angry to 1\n",
    "y_train = tf.keras.utils.to_categorical(y_train) # 1 to [1,0,0,0,0,0,0]\n",
    "y_test = labelencoder.transform(y_test) # angry to 1\n",
    "y_test = tf.keras.utils.to_categorical(y_test) # 1 to [1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "X_train = np.array([np.array(X_train[i], dtype='float32') / 255 for i in range(X_train.shape[0])], dtype='float32')\n",
    "X_test = np.array([np.array(X_test[i], dtype='float32') / 255 for i in range(X_test.shape[0])], dtype='float32')\n",
    "\n",
    "# Convert 3D\n",
    "time_step = 10\n",
    "X_train = X_train.transpose(0,3,1,2)\n",
    "X_train_3D = X_train.reshape((-1,time_step,3,108,192))\n",
    "X_test = X_test.transpose(0,3,1,2)\n",
    "X_test_3D = X_test.reshape((-1,time_step,3,108,192))\n",
    "y_train_3D = y_train.reshape((-1,time_step,7))\n",
    "y_test_3D = y_test.reshape((-1,time_step,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=X_train_3D[0].shape, name='input'))\n",
    "model.add(ConvLSTM2D(filters=20, kernel_size=(3, 3), data_format='channels_first', recurrent_activation='hard_sigmoid',\n",
    "                     activation='tanh', padding='same', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_first'))\n",
    "model.add(ConvLSTM2D(filters=10, kernel_size=(3, 3), data_format='channels_first', padding='same', return_sequences=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling3D(pool_size=(1, 3, 3), padding='same', data_format='channels_first'))\n",
    "model.add(ConvLSTM2D(filters=5, kernel_size=(3, 3), data_format='channels_first', stateful = False,\n",
    "                     kernel_initializer='random_uniform', padding='same', return_sequences=True))\n",
    "model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_first'))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(TimeDistributed(Dense(512,kernel_initializer='glorot_normal', activation = \"relu\")))\n",
    "model.add(TimeDistributed(Dense(y_train_3D.shape[2], kernel_initializer='glorot_normal', activation = \"softmax\")))\n",
    "\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=1E-4), loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_convlstm(X_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=X_train[0].shape, name='input'))\n",
    "    model.add(ConvLSTM2D(filters=20, kernel_size=(3, 3), data_format='channels_first', recurrent_activation='hard_sigmoid',\n",
    "                         activation='tanh', padding='same', return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_first'))\n",
    "    model.add(ConvLSTM2D(filters=10, kernel_size=(3, 3), data_format='channels_first', padding='same', return_sequences=True))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(1, 3, 3), padding='same', data_format='channels_first'))\n",
    "    model.add(ConvLSTM2D(filters=5, kernel_size=(3, 3), data_format='channels_first', stateful = False,\n",
    "                         kernel_initializer='random_uniform', padding='same', return_sequences=True))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same', data_format='channels_first'))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(TimeDistributed(Dense(512,kernel_initializer='glorot_normal', activation = \"relu\")))\n",
    "    model.add(TimeDistributed(Dense(y_train.shape[2], kernel_initializer='glorot_normal', activation = \"softmax\")))\n",
    "\n",
    "    model.compile(tf.keras.optimizers.Adam(learning_rate=1E-4), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7242, 10, 3, 108, 192)\n",
      "(3109, 10, 3, 108, 192)\n",
      "(7242, 10, 7)\n",
      "(3109, 10, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_3D.shape)\n",
    "print(X_test_3D.shape)\n",
    "print(y_train_3D.shape)\n",
    "print(y_test_3D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1E-3, patience=10)           \n",
    "#history = model.fit(x=X_train, y=y_train, batch_size=16, epochs=100, verbose=2, validation_split=0.2, callbacks=[early_stop]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 210/1811 [==>...........................] - ETA: 3:09:05 - loss: 1.9550 - categorical_accuracy: 0.1398"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train_3D, y=y_train_3D, batch_size=4, epochs=100)\n",
    "#history = model.fit(x=X_train, y=y_train, batch_size=128, epochs=100, verbose=2, validation_split=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.predict(x=X_train)\n",
    "train_results = np.argmax(train_results, axis=1)\n",
    "print(f'train prediction is {train_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "train_acc = accuracy_score(y_train, train_results)\n",
    "print(f'train accuracy is {train_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.predict(x=X_test)\n",
    "test_results = np.argmax(test_results, axis=1)\n",
    "print(f'test prediction is {test_results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.argmax(y_test, axis=1)\n",
    "test_acc = accuracy_score(y_test, test_results)\n",
    "print(f'test accuracy is {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    plt.figure(figsize=(9,9))\n",
    "    plt.figure(1)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    plt.title(title, fontsize=18)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=12)\n",
    "    plt.yticks(tick_marks, classes, fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=16, labelpad=20)\n",
    "    plt.xlabel('Predicted label', fontsize=16, labelpad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "    plt.show(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, test_results)\n",
    "plot_confusion_matrix(cm, classes = list(labelencoder.classes_), normalize=False, title = 'confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cr = classification_report(y_test, test_results, target_names=list(labelencoder.classes_))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_train, train_results)\n",
    "plot_confusion_matrix(cm, classes = list(labelencoder.classes_), normalize=False, title = 'confusion matrix')\n",
    "\n",
    "cr = classification_report(y_train, train_results, target_names=list(labelencoder.classes_))\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
